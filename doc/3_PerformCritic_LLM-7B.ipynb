{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f94d8c",
   "metadata": {},
   "source": [
    "# Perform LLM with Learning by Examples\n",
    "\n",
    "Adapter le modele génératif de langage pour ajouter un module \"auto-critic\". Concretement, cela consiste à ajouter une sortie à derniere sequence de decodeur. Entrainer le modele en figeant les poids du LLM (TransfertLearning), puis fineTuner le modele complet.\n",
    "\n",
    "![LLM-Critic](LLM-AutoCritic.png)\n",
    "\n",
    "**Dans cette derniere étape, nous verrons comment les modeles s'améliore aujourd'hui, mais nous verrons comment implementer notre approche pour améliorer les modeles**\n",
    "\n",
    "*Nous aborderons les points suivants : *\n",
    "\n",
    "    - Comment utiliser ?\n",
    "    - Comment créer ?\n",
    "    - Comment lancer ?\n",
    "    \n",
    " ### Bibliographie :\n",
    " \n",
    " \n",
    " - [Self-Instruct](https://arxiv.org/abs/2212.10560)\n",
    " - [HumanFeedBack](https://arxiv.org/abs/2203.02155) \n",
    " \n",
    " ### Prérequis : \n",
    "\n",
    "\n",
    "    - Python 3.8\n",
    "    - Pytorch 2.0 (&TorchVision)\n",
    "    - EasyInstruct\n",
    "    - 8Gb RAM\n",
    "\n",
    "## Examples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e28851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyinstruct import llamaEngine\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac011d9",
   "metadata": {},
   "source": [
    "https://huggingface.co/decapoda-research/llama-7b-hf/tree/main\n",
    "\n",
    "LlamaForCausalLM(\n",
    "\n",
    "  (model): LlamaModel(\n",
    "  \n",
    "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
    "    \n",
    "    (layers): ModuleList(\n",
    "    \n",
    "      (0-31): 32 x LlamaDecoderLayer(\n",
    "      \n",
    "        (self_attn): LlamaAttention(\n",
    "        \n",
    "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          (rotary_emb): LlamaRotaryEmbedding()\n",
    "        )\n",
    "        \n",
    "        (mlp): LlamaMLP(\n",
    "        \n",
    "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
    "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
    "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
    "          (act_fn): SiLUActivation()\n",
    "        )\n",
    "        \n",
    "        (input_layernorm): LlamaRMSNorm()\n",
    "        \n",
    "        (post_attention_layernorm): LlamaRMSNorm()\n",
    "        \n",
    "      )\n",
    "    )\n",
    "    \n",
    "    (norm): LlamaRMSNorm()\n",
    "    \n",
    "  )\n",
    "  \n",
    "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167ca546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 # Step1: Initialize according to the your model path and the weight format</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # Load the model in hf format</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 lengine=llamaEngine(base_path=YOUR_BASE_PATH,adapter_path=YOUR_ADAPTER_PATH,gpu=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,mul     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'YOUR_BASE_PATH'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# Step1: Initialize according to the your model path and the weight format\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# Load the model in hf format\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 lengine=llamaEngine(base_path=YOUR_BASE_PATH,adapter_path=YOUR_ADAPTER_PATH,gpu=\u001b[94mTrue\u001b[0m,mul     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'YOUR_BASE_PATH'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step1: Initialize according to the your model path and the weight format\n",
    "# Load the model in hf format\n",
    "lengine=llamaEngine(base_path=YOUR_BASE_PATH,adapter_path=YOUR_ADAPTER_PATH,gpu=True,multi_gpu=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
